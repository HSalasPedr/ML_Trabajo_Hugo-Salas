---
title: "ML_Trabajo_Hugo Salas"
author: "Hugo Salas"
date: "2023-02-25"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Título
Introducción del tema y objetivo

```{r cargar los datos, echo = FALSE}
col_names <- c("Code", "ClumpThickness","CellSizeUniformity", "CellShapeUniformity",
               "MarginalAdhesion", "SingleEpithelialCellSize", "BareNuclei",
               "BlandChromatin", "NormalNucleoli", "Mitoses", "Group", "Class")

data_train <- readLines("DATA/Breast_Cancer_train.data")
# read.csv solo permite usar separadores de 1 byte, así que tenemos que recurrir a otras opciones
data_train <- gsub("h_", ",", data_train)
data_train <- textConnection(data_train)
data_train <- read.csv(data_train,
                       header = FALSE)
names(data_train) <- col_names

library(stringr)
data_test <- readLines("DATA/Breast_Cancer_test.data")
data_test <- str_replace_all(data_test, "[[:punct:]]", ",")
data_test <- textConnection(data_test)
data_test <- read.csv(data_test,
                       header = FALSE)
NAcols <- (1:ncol(data_test))%%2
data_test <- data_test[!NAcols == 0]
names(data_test) <- col_names[-length(col_names)]
```

Una vez cargados los datos y darles el formato adecuado para su uso, comprobaremos que todos son de tipo numérico, y cambiaremos el tipo de los que no lo sean.

```{r tipos de datos,echo = fALSE, warning = FALSE}
for (col in names(data_train)){
  if (class(data_train[, col]) != "integer"){
  data_train[, col] <- as.numeric(data_train[, col])
  }
}

for (col in names(data_test)){
  if (class(data_test[, col]) != "integer"){
  data_test[, col] <- as.integer(data_test[, col])
  }
}
summary(data_train)
print("------------------------------------------------------")
summary(data_test)
```
Posteriormente, factorizaremos las variables necesarias. En este caso, se considera que las variables Class y Group deben tomarse como factores. Se omite la variable Code, que no se incluirá en el modelo final.

```{r}
data_train$Class <- as.factor(data_train$Class)
data_train$Group <- as.factor(data_train$Group)
```

El programa nos indica que ha introducido NAs en varias columnas del dataset de entrenamiento, ya que contenían datos no numéricos. Por ejemplo, en la columna BareNuclei, había varias celdas cuyo valor era "?".

Ahora nos encargaremos de cambiar los valores introducidos por error en aquellas casillas que los contengan. Por ejemplo, sabiendo que los valores que puede tomar una variable se encuentran en el rango [1, 10], un valor de 80 probablemente indique que quien haya introducido un dato haya puesto un cero de más y el valor real sea 8.

```{r, echo = FALSE}
data_train$BlandChromatin[which(data_train$BlandChromatin == 11)] <- 1
data_train$Class[which(data_train$Class == 44)] <- 4
data_train$Class[which(data_train$Class == 20)] <- 2
data_train$Class[which(data_train$Class == 3)] <- NA
data_train$CellShapeUniformity[which(data_train$Class == -7)] <- 7
data_train$Class <- droplevels(data_train$Class)

for (col in names(data_train)[-c(1, 11, 12)]){
  values <- data_train[, col][which(data_train[, col] > 10)]
  data_train[, col][which(data_train[, col] > 10)] <- values/10
}

summary(data_train)
```

Estandarizamos las variables numéricas para que sus valores sean comparables posteriormente. Además, se eliminará la columna Code, que no se empleará en el modelo.

```{r, echo = FALSE}
estandariza <- function(valores){
  output <- (valores - mean(valores, na.rm = TRUE))/sd(valores, na.rm = TRUE)
  return(output)
}

data_est <- data_train[,-c(1, 11, 12)]
for (var in names(data_est)){
  new_var_name <- paste0("est_", var)
  est_var <- estandariza(data_est[[var]])
  data_train[, new_var_name] <- est_var
}

final_data_train <- data_train[, 11:21]
```

El siguiente paso será imputar los NAs que se hayan producido. Comprobamos las distribuciones de los datos para elegir el método a utilizar para imputar los NAs.

```{r echo = FALSE}
for (col in names(final_data_train)[-c(1, 2)]){
  hist(data_train[,col],
       main = paste0("Distribución de ", col))
}
plot(final_data_train$Class)
plot(final_data_train$Group)
```

Ahora toca lidiar con los missing values. En este caso, como los datos faltantes no son tantos y las distribuciones son asimétricas, sustituiremos las celdas en las que aparezca un NA por el valor de la mediana de la columna en la que se encuentren. Aunque se altere la naturaleza de los datos, el desvío será mínimo, pues no hay un gran número de datos faltantes.

Para la columna Class, se opta por eliminar las filas en las que se hallen missing values.

```{r Imputar NAs, echo = FALSE}
for (col in names(final_data_train)[-c(1, 2)]){
  if (sum(is.na((final_data_train[, col]))) != 0){
    median_col <- median(final_data_train[, col],
                      na.rm = TRUE)
    final_data_train[, col][is.na(final_data_train[, col])] <- median_col
  }
}

final_data_train <- final_data_train[-which(is.na(final_data_train$Class)),]
levels(final_data_train$Class) <- c("Benign", "Malignant")

summary(final_data_train)
```
Observamos que ya no quedan missing values. El siguiente paso será entrenar el modelo.

## Entrenamiento del modelo

Por la naturaleza de la variable regresora, que es un factor, se opta por un modelo logístico. Para automatizar el proceso, se emplea la función "step" de R, que selecciona un modelo mediante procedimientos step-wise con base en su AIC.

```{r, echo = FALSE, warning = FALSE}
data_train2 <- final_data_train
intercept_only <- glm(Class ~ 1, data = data_train2, family = binomial(link="logit"))
all <- glm(Class ~ ., data = data_train2, family = binomial(link = "logit"))

backward <- step(all, direction = "backward", scope = formula(all), trace = 0)

both <- step(intercept_only, direction = "both", scope = formula(all), trace = 0)
```

```{r, echo = FALSE}
intercept_only$anova
backward$coefficients
backward$anova

both$anova
```
Finalmente, el modelo obtenido contempla los siguiente parámetros:

```{r}
both$formula
```


## Cross validation

Creamos datasets de test y de entrenamiento para comprobar la capacidad de predicción del modelo. Para ello, primero se crea una función que recoja los datos de las matrices de confusión que se obtengan del entrenamiento del modelo, y calcule las métricas necesarias para su evaluación. Posteriormente, se dividirá el conjunto de datos de entrenamiento de forma que se emplee el 80% de los datos para el entrenamiento y el 20% restante para el test.

```{r echo=FALSE}
get_table_info <- function(confusion_table){
  # accuracy <-  (TP + TN)/n
  # precission = TP/(TP + FP)
  # FDR <-  FP/(TP + FP)
  # Sensitivity(recall) <-  TP/(TP + TN)
  # specificity <-  TN/(TN + FN)
  out_df <- data.frame(accuracy = NA,
                         recall = NA,
                         specificity = NA,
                         fdr = NA,
                         precission = NA)
  TP = confusion_table["1", "1"]
  TN = confusion_table["0", "0"]
  FP = confusion_table["0", "1"]
  FN = confusion_table["1", "0"]
  n = TP + TN + FP + FN
  out_df$accuracy <- (TP + TN)/n
  out_df$precission <-  TP/(TP + FP)
  out_df$fdr <-  FP/(TP + FP)
  out_df$recall <-  TP/(TP + TN)
  out_df$specificity <-  TN/(TN + FN)
  return(out_df)
}
```

```{r}
data_cv <- final_data_train
final_statistics <- data.frame()

vec_all <- 1:nrow(data_cv)
data_target_df <- data.frame(ifelse(final_data_train$Class == "Malignant", 1, 0))
data_cv[,"Class"] <- data_target_df

for (i in seq_along(1:5)){
  test_ind <- sample(vec_all, floor(length(vec_all)/5))
  vec_all <- vec_all[-test_ind]
  
  y_test <- data_cv$Class[test_ind]
  y_train <- data_cv$Class[-test_ind]
  x_test <- data_cv[test_ind, ]
  x_train <- data_cv[-test_ind, ]
  
  data_model <- cbind(y_train, x_train)
  
  model_train <- both
  
  model_predictions <- predict(model_train, newdata = x_test, type = "response")
  
  plot(sort(model_predictions), type = "l")
  abline(h = 0.5, col = "red")
  
  threshold <- 0.5
  predictions01 <- ifelse(model_predictions > threshold, 1, 0)
  output <- get_table_info(table(y_test, predictions01))
  final_statistics <- rbind(final_statistics, output)
}

final_statistics
```




