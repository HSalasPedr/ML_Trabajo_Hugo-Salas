---
title: "ML_Trabajo_Hugo Salas"
author: "Hugo Salas"
date: "2023-02-25"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

El código empleado para la realización de este trabajo puede encontrarse en el siguiente enlace: 
[GitHub Link](https://github.com/HSalasPedr/ML_Trabajo_Hugo-Salas.git)

## Título

```{r cargar los datos, echo = FALSE}
col_names <- c("Code", "ClumpThickness","CellSizeUniformity", "CellShapeUniformity",
               "MarginalAdhesion", "SingleEpithelialCellSize", "BareNuclei",
               "BlandChromatin", "NormalNucleoli", "Mitoses", "Group", "Class")

data_train <- readLines("DATA/Breast_Cancer_train.data")
# read.csv solo permite usar separadores de 1 byte, así que tenemos que recurrir a otras opciones
data_train <- gsub("h_", ",", data_train)
data_train <- textConnection(data_train)
data_train <- read.csv(data_train,
                       header = FALSE)
names(data_train) <- col_names

library(stringr)
data_test <- readLines("DATA/Breast_Cancer_test.data")
data_test <- str_replace_all(data_test, "[[:punct:]]", ",")
data_test <- textConnection(data_test)
data_test <- read.csv(data_test,
                       header = FALSE)
NAcols <- (1:ncol(data_test))%%2
data_test <- data_test[!NAcols == 0]
names(data_test) <- col_names[-length(col_names)]
```

Una vez cargados los datos y darles el formato adecuado para su uso, comprobaremos que todos son de tipo numérico, y cambiaremos el tipo de los que no lo sean.

```{r tipos de datos,echo = FALSE, warning = FALSE}
for (col in names(data_train)){
  if (class(data_train[, col]) != "integer"){
  data_train[, col] <- as.numeric(data_train[, col])
  }
}

for (col in names(data_test)){
  if (class(data_test[, col]) != "integer"){
  data_test[, col] <- as.integer(data_test[, col])
  }
}
print("Resumen de los datos de entrenamiento")
summary(data_train)
```

Antes de iniciar cualquier cambio al conjunto de datos de entrenamiento, se identificó que había casos que pertenecían al mismo sujeto. Entre ellos, había tres registros exactamente iguales. Se optó por mantenerlos, pues podrían tatarse del mismo sujeto participando en distintos estudios, y que estuviera padeciendo una evolución en su enfermedad. Por otra parte, el código de identificación del paciente no es relevante a la hora de entrenar el modelo, y las tres filas exactamente iguales no deberían suponer un problema de overfitting al entrenar el modelo.

```{r, echo = FALSE, message = FALSE}
library(dplyr)
print(paste0("Número de casos en el dataset de entrenamiento: ", nrow(data_train)))
print(paste0("Número de pacientes no repetidos en el dataset de entrenamiento: ", length(unique(data_train$Code))))
print(paste0("Número de casos no repetidos en el dataset de entrenamiento: ", data_train %>% distinct() %>% nrow()))
```


Posteriormente, factorizaremos las variables necesarias. En este caso, se considera que las variables Class y Group deben tomarse como factores. Se omite la variable Code, que no se incluirá en el modelo final.

```{r factorizar, echo = FALSE}
data_train$Class <- as.factor(data_train$Class)
data_train$Group <- as.factor(data_train$Group)
```

El programa nos indica que ha introducido NAs en varias columnas del dataset de entrenamiento, ya que contenían datos no numéricos. Por ejemplo, en la columna BareNuclei, había varias celdas cuyo valor era "?".

Ahora nos encargaremos de cambiar los valores introducidos por error en aquellas casillas que los contengan. Por ejemplo, sabiendo que los valores que puede tomar una variable se encuentran en el rango [1, 10], un valor de 80 probablemente indique que quien haya introducido un dato haya puesto un cero de más y el valor real sea 8.

```{r arreglar train, echo = FALSE}
data_train$BlandChromatin[which(data_train$BlandChromatin == 11)] <- 1
data_train$Class[which(data_train$Class == 44)] <- 4
data_train$Class[which(data_train$Class == 20)] <- 2
data_train$Class[which(data_train$Class == 3)] <- NA
data_train$CellShapeUniformity[which(data_train$Class == -7)] <- 7
data_train$Class <- droplevels(data_train$Class)

for (col in names(data_train)[-c(1, 11, 12)]){
  values <- data_train[, col][which(data_train[, col] > 10)]
  data_train[, col][which(data_train[, col] > 10)] <- values/10
}

summary(data_train)
```

Estandarizamos las variables numéricas para que sus valores sean comparables posteriormente. Además, se eliminará la columna Code, que no se empleará en el modelo.

```{r estandarizar, echo = FALSE}
estandariza <- function(valores){
  output <- (valores - mean(valores, na.rm = TRUE))/sd(valores, na.rm = TRUE)
  return(output)
}

data_est <- data_train[,-c(1, 11, 12)]
for (var in names(data_est)){
  new_var_name <- paste0("est_", var)
  est_var <- estandariza(data_est[[var]])
  data_train[, new_var_name] <- est_var
}

final_data_train <- data_train[, 11:21]
```

El siguiente paso será imputar los NAs que se hayan producido. Comprobamos las distribuciones de los datos para elegir el método a utilizar para imputar los NAs.

```{r distribuciones train, echo = FALSE}
par(mfrow = c(3, 4))

for (col in names(final_data_train)[-c(1, 2)]){
  hist(final_data_train[,col],
       main = paste0("Distribución de ", col))
}
plot(final_data_train$Class)
plot(final_data_train$Group)
```

Ahora toca lidiar con los missing values. En este caso, como los datos faltantes no son tantos y las distribuciones son asimétricas, sustituiremos las celdas en las que aparezca un NA por el valor de la mediana de la columna en la que se encuentren. Aunque se altere la naturaleza de los datos, el desvío será mínimo, pues no hay un gran número de datos faltantes.

Para la columna Class, se opta por eliminar las filas en las que se hallen missing values.

```{r Imputar NAs, echo = FALSE}
for (col in names(final_data_train)[-c(1, 2)]){
  if (sum(is.na((final_data_train[, col]))) != 0){
    median_col <- median(final_data_train[, col],
                      na.rm = TRUE)
    final_data_train[, col][is.na(final_data_train[, col])] <- median_col
  }
}

final_data_train <- final_data_train[-which(is.na(final_data_train$Class)),]
levels(final_data_train$Class) <- c("Benign", "Malignant")

summary(final_data_train)
```
Observamos que ya no quedan missing values. El siguiente paso será entrenar el modelo.

## Entrenamiento del modelo

Por la naturaleza de la variable regresora, que es un factor, se opta por un modelo logístico. Para automatizar el proceso, se emplea la función "step" de R, que selecciona un modelo mediante procedimientos step-wise con base en su AIC.

```{r entrenar modelo, echo = FALSE, warning = FALSE}
data_train2 <- final_data_train
intercept_only <- glm(Class ~ 1, data = data_train2, family = binomial(link="logit"))
all <- glm(Class ~ ., data = data_train2, family = binomial(link = "logit"))

backward <- step(all, direction = "backward", scope = formula(all), trace = 0)

both <- step(intercept_only, direction = "both", scope = formula(all), trace = 0)
```

```{r mostrar resultados del entrenamiento, echo = FALSE}
intercept_only$anova
backward$coefficients
backward$anova

both$anova
```
Finalmente, el modelo obtenido contempla los siguiente parámetros:

```{r mostrar modelo, echo = FALSE}
both$formula
```

Se observa si hay grupos de dos variables que interaccionen entre sí, para ello, se exporta una imagen en formato pdf que compara dichas variables dos a dos. En ella, no se observan tendencias claras que justifiquen la adición de términos de interacción al modelo entrenado.

```{r, echo = FALSE, message = FALSE}
library(ggplot2)
library(GGally)

pdf("my_plot.pdf",         # File name
    width = 20, height = 15, # Width and height in inches
    bg = "white",          # Background color
    colormodel = "cmyk",    # Color model (cmyk is required for most publications)
    paper = "A4")          # Paper size

ggpairs(final_data_train)

dev.off()
```

```{r}
knitr::include_graphics("my_plot.pdf")
```

## Cross validation

Creamos datasets de test y de entrenamiento para comprobar la capacidad de predicción del modelo. Para ello, primero se crea una función que recoja los datos de las matrices de confusión que se obtengan del entrenamiento del modelo, y calcule las métricas necesarias para su evaluación. Posteriormente, se dividirá el conjunto de datos de entrenamiento de forma que se emplee el 80% de los datos para el entrenamiento y el 20% restante para el test.

```{r función para recoger métricas, echo = FALSE}
get_table_info <- function(confusion_table){
  # accuracy <-  (TP + TN)/n
  # precission = TP/(TP + FP)
  # FDR <-  FP/(TP + FP)
  # Sensitivity(recall) <-  TP/(TP + TN)
  # specificity <-  TN/(TN + FN)
  out_df <- data.frame(accuracy = NA,
                         recall = NA,
                         specificity = NA,
                         fdr = NA,
                         precission = NA)
  TP = confusion_table["1", "1"]
  TN = confusion_table["0", "0"]
  FP = confusion_table["0", "1"]
  FN = confusion_table["1", "0"]
  n = TP + TN + FP + FN
  out_df$accuracy <- (TP + TN)/n
  out_df$precission <-  TP/(TP + FP)
  out_df$fdr <-  FP/(TP + FP)
  out_df$recall <-  TP/(TP + TN)
  out_df$specificity <-  TN/(TN + FN)
  return(out_df)
}
```

```{r cross validation, echo = FALSE}
data_cv <- final_data_train
final_statistics <- data.frame()

vec_all <- 1:nrow(data_cv)
data_target_df <- data.frame(ifelse(final_data_train$Class == "Malignant", 1, 0))
data_cv[,"Class"] <- data_target_df
par(mfrow = c(2, 3))
for (i in seq_along(1:5)){
  test_ind <- sample(vec_all, floor(length(vec_all)/5))
  vec_all <- vec_all[-test_ind]
  
  y_test <- data_cv$Class[test_ind]
  y_train <- data_cv$Class[-test_ind]
  x_test <- data_cv[test_ind, ]
  x_train <- data_cv[-test_ind, ]
  
  data_model <- cbind(y_train, x_train)
  
  model_train <- both
  
  model_predictions <- predict(model_train, newdata = x_test, type = "response")
  
  plot(sort(model_predictions), type = "l")
  abline(h = 0.5, col = "red")
  
  threshold <- 0.5
  predictions01 <- ifelse(model_predictions > threshold, 1, 0)
  output <- get_table_info(table(y_test, predictions01))
  final_statistics <- rbind(final_statistics, output)
}

final_statistics
```

## Datos de test

A continuación, prepararemos el dataset de test para realizar las predicciones. Se seguirá el mismo pipeline que se siguió con los datos de entrenamiento. La principal diferencia será que en este caso se opta por no imputar missing values. Para los datos de test, también se identificaron sujetos repetidos. Sin embargo, con tal de reportar todas las predicciones requeridas, no fueron eliminadas. Además, no tendrían efecto sobre el entrenamiento del modelo.

```{r arreglar datos de test, echo = FALSE}
data_test$Group <- as.factor(data_test$Group)
```

```{r, echo = FALSE}
for (col in names(data_test)[-c(1, 11)]){
  values <- data_test[, col][which(data_test[, col] > 10)]
  data_test[, col][which(data_test[, col] > 10)] <- values/10
}
```

```{r, echo = FALSE}
data_est_test <- data_test[,-c(1, 11)]
for (var in names(data_est_test)){
  new_var_name <- paste0("est_", var)
  est_var <- estandariza(data_est_test[[var]])
  data_test[, new_var_name] <- est_var
}

final_data_test <- data_test[, 11:20]
```

```{r, echo = FALSE}
par(mfrow = c(3, 4))

for (col in names(final_data_test)[-c(1, 2)]){
  hist(final_data_test[,col],
       main = paste0("Distribución de ", col))
}

plot(final_data_test$Group)
```

```{r datos de test finales, echo = FALSE}
print("Resumen de los datos procesados")
summary(final_data_test)
```

## Predicciones

A continuación, se procede a predecir si los casos propuestos en el dataset de test son pacientes positivos en cáncer de mama.

```{r predicciones con los datos de test, echo = FALSE}
test_predictions <- predict(model_train, newdata = final_data_test, type = "response")
test_predictions01 <- ifelse(test_predictions > 0.5, 1, 0)
print("Resultados de las predicciones (0 = negativo, 1 = positivo)")
table(test_predictions01)
```

Por último, se añaden los datos de las predicciones a una tabla para comparar con los datos reales. Se exporta esta tabla en formato csv.

```{r, echo = FALSE}
csv_export <- data.frame(Code = data_test$Code, Prediction = test_predictions01)
write.csv(csv_export, "ML1_Results_HugoSalas", row.names = FALSE)
```

